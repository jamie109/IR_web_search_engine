## Web搜索引擎 （期末⼤作业）
## 建议退课！ 建议退课！ 建议退课！ 
### 食用指南
1. 先运行spider.py，获取网页内容。

   * 可自行更改`cc_base_url = 'http://cc.nankai.edu.cn'`和`to_use_url_list = ['http://cc.nankai.edu.cn']`中的链接。
   这是你要爬取的网页，可以改成南开电光学院、人工智能学院等等。
   * `if to_use_url_list is not None and mycount < 50`中mycount小于多少可以自定义，这是你想要爬取的网页数目。
   * `sleep(random.randint(2, 3))`中的2和3也可以更改，这是爬完一个网页等待一会儿的时间，谓之”爬虫礼仪也“。（去掉这行代码会快一些。）

2. 运行content_inverted_index.py，对网页文本内容构造倒排索引。
3. 运行page_rank.py，进行链接分析，把结果保存本地文件夹。
4. 运行main.py，进行查询。

### 实验要求和实现思路
#### 1. 网页抓取(10%) 2023.1.30 finish
##### 要求

根据搜索引擎主题选择⽹站进⾏爬取，爬取网页数⽬不限制，注意不要违法，主题不会作为评分标准，不需要太过纠结爬什么。

##### 思路

* 爬取流程
   * 准备
  
   首先需要一个集合`used_url_set`记录已经爬取过的网页，一个列表`to_use_url_list`记录将要爬取的网页。
   初始时`used_url_set`为空，`to_use_url_list`中只有一个网页A。

   * 爬取A 
  
   A的标题，去掉符号，作为存储相关数据（html、文本内容等）的文件名。 
   html文件存到dataset/html_data文件夹下面。 
   该网页的url（例如http://cc.nankai.edu.cn，存到第一行）和文本内容（存到第二行）存在dataset/web_data文件夹下面。
   其命名为'数字_去掉了标点符号的网页标题.html/txt'，数字表示这是第几个爬取的网页。

   A中可能会有很多跳转到其他地方的链接BCD等等，如果以前没有爬过（它们不在`used_url_set`中），要把它们加到`to_use_url_list`中。

   * 爬完A
  
   把A从`to_use_url_list`删掉，加到`used_url_set`中。
   接着，如果`to_use_url_list`不为空，就从中选取一个url接着爬，我用的是第0个。

#### 2. 文本索引

##### 要求

对网页及其锚文本构建索引，可以按锚文本、⽹⻚标题、URL 等域构建索引。

###### 来自chatgpt的回答
1. 使用Python的urllib库获取网页，使用BeautifulSoup解析网页，获取页面中的文本和锚文本；
2. 用正则表达式过滤掉不需要的文本，比如标签，脚本等；
3. 对锚文本和文本分别进行分词，比如使用NLTK库；
4. 将分词结果构建成索引，比如使用倒排索引；
5. 使用索引搜索锚文本和文本，返回搜索结果。

所以，我要先分词，再弄索引？
##### 思路
1. 对于标题的查询

类似hw3，我抄我自己。感谢认真写hw3代码的wjm，让我有代码可抄。
上链接————[空间向量模型](https://github.com/jamie109/IR_VSM)，里面有报告有我写代码的思路。

这个比hw3简单一些，因为它只有标题，不需要进行不同域的组合。

最后把余弦相似度列表转换成字典，id对应余弦相似度。保存到了本地文件dataset/title_cos_sim_dic.pkl。

2. 锚文本 url

还没写，我还不知道去哪里找锚文本呢(lll￢ω￢)
截止2023.2.1 18：10 我还没写锚文本跟url。

3. 文本内容
这里可能需要倒排索引，我昨天写的那个有问题，明天在改。
* 倒排索引
  * 用一个字典inverted_index（某个单词:\[包含这个单词的的文件\]）保存倒排索引的内容。
  * 遍历/dataset/web_data/文件夹下的所有文件（txt文件，存的是网页文本内容）。
  * 对每一个txt文件，获取其内容content，然后去掉标点、英文字母大写改小写，然后分词（掉包，jieba.lcut_for_search(content)），就会得到单词列表。
  * 对每一个单词，把这个txt文件名中的数字添加到inverted_index中这个单词对应的列表中。
  * 注意这里添加的是文件名中的数字，比如0_计算机学院主页.txt，就加0。因为这个0对应着它的url，根据数字就可以返回链接。
* [倒排索引原理](https://cloud.tencent.com/developer/article/1587656)
* content_inverted_index.py，注释里有，懒得写了，bye。

##### 一些重要的点
1. 文件读取顺序
我对于这个网页的索引，是根据爬取它的先后顺序记录的。就是0、1、2、3……，文件名字是`0_计算机学院主页.txt`格式。
我在读取本地txt文件时，它的读取顺序不太对。
解决:
```python
# 按照文件名开头数字排序
file_name_list.sort(key=lambda x: int(x.split('_')[0]))
```
2. id、title、url、文本内容的对应关系。

|dict|function|
|----|----|
|id_url_dic|根据url查找id|
|url_id_dic|根据id查找url|
|title_id_dic|根据id查找title，目前没有用到根据title找id的|

对文本内容，它的文件名就是`id_标题.txt`。

我在想，是不是写一个 IdMap class 会简单一些？
但如果重写，还得改代码，麻烦，我懒得写了。感觉这两种方式差不多，IdMap里面也是一个字典+列表，我这是两个字典。

3. 查询时间过长

一开始我没用倒排索引，查询文本内容非常慢，查一次用时将近50s。使用倒排索引后，速度提升很快，其实还是有改进空间的，
比如对倒排索引的索引单词的遍历，是哈希还是有二叉树等等方法应该可以实现加速，我就用的直接一个一个遍历。
还需要注意的是倒排索引再爬虫结束后，构建一次就可以，每次查询直接调用结果就可以了。
不要把内容查询跟倒排索引写在一个py下，要不然每次查询都要进行一次倒排索引构建，耗时费事还没意义。

#### 3. 链接分析
##### 要求
使⽤PageRank进⾏链接分析，评估⽹⻚权重。
##### 思路
见page_rank.py。

#### 4. 查询服务
##### 标题+文本内容+网页权重。
##### 站内查询、短语查询、通配查询、查询日志、⽹⻚快照等
* 站内查询应该就是我实现的标题+文本内容+网页权重的查询。
* 短语查询

`match_phrase 查询首先将查询字符串解析成一个词项列表，然后对这些词项进行搜索，
但只保留那些包含全部搜索词项，且位置与搜索词项相同的文档，且中间不许夹杂其他词。`

位置还要相同，这在构建索引的时候，就得记录这是哪个文档的第几个词，好麻烦啊，不写这个。

不打算写这个了，还要重新改倒排索引记录，增加单词在文档中的位置，查的时候还要再找，应该挺耗时的，放弃它了。

* 通配查询

`匹配字段被通配符表达式（没有被分析）匹配的文档。支持的通配符为*（匹配任意字符序列，包括空字符序列）以及？（匹配任意单字符）。
注意，此查询可能会很慢，它需要迭代许多字段值。
为了防止极慢的通配符匹配，通配符字段值不能以一个通配符作为开头。`

关键是调用fnmatch库，没有我想象得那么难，它可以实现任意通配符号得匹配。python得各种库真的很方便。

```python
from fnmatch import fnmatch
def proc_wildcard(words_list, str_with_wildcard):
    """
    通配符号处理
    :param str_with_wildcard: 带有通配符号的字符串
    :return: 处理后的包含在单词集合中的单词列表
    """
    processed_list = []
    for item in words_list:
        if fnmatch(item, str_with_wildcard):
            processed_list.append(item)
    return processed_list
```
* 查询日志 finish
* 网页快照 

`网页快照，是搜索引擎在收录网页时，对该网页进行索引，然后存入服务器缓存里，网页快照因此也只能显示网页的最新收录结果。`

这个怎么实现，我是爬完在查询，没有网页的更新。不写了，(￢︿̫̿￢☆)
##### 前端

我用的是tkinter，上学期数据库大作业也用的它。优点是简单，缺点是界面丑陋(T_T)。

总结：从一个窗口跳到另一个窗口。

###### 记录比较重要的点

* 我在一个Tk()窗口，点击某个按钮或者做了什么操作，需要弹出一个消息窗口如tkinter.messagebox.showinfo(message="消息")，直接把showinfo加进去，
它不仅会弹出这个消息提示框还会弹出一个空的Tk()窗口。解决方法是在tkinter.messagebox.showinfo函数前加两行代码。

``python
 # 解决出现两个弹窗的问题
    root = Tk()
    root.withdraw()
``

* 窗口中输入的信息无法在该窗口函数中保存，因为此时它是空的。比如有一个sign_in函数，在这个函数里，建了一个Tk()窗口，它有输入控件，
如果我在这个sign_in函数窗口对象的后面，直接写代码要保存输入的内容，比如user_name = e1.get()（e1是个输入空间），此时user_name 就是一个
空的字符串。如果需要保存，就得从这个sign_in函数出去，比如在sign_in函数调用另一个函数A，然后A函数来获取输入字符串，就不是空的了。具体什么原因我也不太懂。

* 接上一条，注意在A函数获取输入字符串之前，不能关闭sign_in函数的Tk()窗口，不然就会报错，最好在A函数中根本不关Tk()窗口（不写parent.destroy()）。
反正我觉得写不写的无所谓，不写最好，大不了手动关闭（鼠标点击(lll￢ω￢)），更何况我可能在A函数中把parent（sign_in的TK()窗口）传到别的函数里，
然后在那个函数中关了呢。

##### 用户登录
新建一个类（成员有用户名、年龄、性别），用一个字典保存用户信息。

用户登录时检查是否注册过（字典的键是否包含输入的用户名），没注册就需要用户输入姓名、年龄、性别，更新用户信息字典。

##### 个性化查询
目前思路是，根据用户年龄和性别，推送不同的内容。

年龄18—22，差不多是本科生，在查询关键词中给它额外加个”本科“。
年龄23-30，研究生，博士生，查询关键词中额外加个”教授“、”研究生“啥的。
大于30的，家长，老师什么的，加个”发展“、”学科“。

性别，好像没什么好推的，目前没想到。

##### 个性化推荐

可以固定推荐的网页吗？什么”猜你喜欢“、“你可能感兴趣”。

给年龄小于30的推荐什么开学典礼、学生奖学金、大师讲座啊。大于30的推荐什么南开获取了什么成就，关于院士教授啥的，双一流balabala。
